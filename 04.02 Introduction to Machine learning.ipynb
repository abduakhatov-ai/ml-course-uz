{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Machine learning is a field of study that gives computers the ability to learn without being explicitly programmed\n",
    "\n",
    "> *Arthur Samuel, 1959*\n",
    "\n",
    "# Машинное обучение\n",
    "**Машинное обучение** это область искусственного интелекта, которая изучает алгоритмы, способные решать определенный круг задач без явного программирования того, как именно нужно решать эти задачи. Алгоритмы сами обучаются путем выявления закономерностей (паттернов, шаблонов) в данных. Термин машинное обучение ввел в обиход Артур Самуэль 1959 году, который занимался исследованием искусственного интеллекта в корпорации IBM. Он был одним из пионеров в области машинного обучения и создал программу для игры в шашки, которая является одним из первых примеров самообучающейся программы. \n",
    "\n",
    "Ниже представлена диаграмма, которая показывает место машинного обучения среди других областей искуственного интеллекта (диаграмма взята из книги <a href=\"http://www.deeplearningbook.org/contents/intro.html\">Deep Learning</a>)\n",
    "\n",
    "<img src=\"img/ai_fields.png\" />\n",
    "\n",
    "Том Митчел в <a href=\"http://www.cs.cmu.edu/~tom/mlbook.html\">своей книге</a> дал более формальное и широко цитирумое определение машинного обучения:\n",
    "> Говорят, что программа обучается на опыте $E$ относительно класса задач $T$ в смысле меры качества $L$, если при решении задачи $T$ качество, измеряемое мерой $L$, возрастает при демонстрации нового опыта $E$.\n",
    "\n",
    "> A computer program is said to learn from experience $E$ with respect to some class of tasks $T$ and performance measure $L$ if its performance at tasks in $T$, as measured by $L$, improves with experience $E$.\n",
    "\n",
    "Давайте разберем это определение, чтобы лучше понять о чем идет речь\n",
    "1. Опыт $E$ - часто это набор данных, на которых алгоритм обучается путем поиска закономерностей (паттернов)\n",
    "2. Задача $T$ - задача, решаемая машинным обучением. Эти задачи классифицируют по нескольким категориям, основными из которых можно выделить регрессию, классификацию и обучение с подкреплением\n",
    "3. Мерой $L$ - мера, которая позволяет оценить насколько хорошо или точно данный метод выполняет задачу $T$\n",
    "\n",
    "В качестве примера можно привести задачу предсказания цен квартир. Цена квартиры зависит от нескольких факторов. Очевидными факторами являются такие параметры как площадь квартиры, этаж, год постройки, местоположение и т.д. Эти данные, которые влияют на цену, соответствуют опыту $E$. Так как параметры представляют из себя массив чисел, то данные по каждой квартире можно представить в виде вектора $\\vec{x} \\in \\mathbb{R^n}$, где $n$ соответствует количеству параметров для одной квартиры. Задачей $T$ является предсказания цены квартиры из данных параметров. Фактическую цену одной квартиры можно обозначить символом $y$, а предсказанную символом $\\hat{y}$. В качестве меры $L$ в данном случае можно использовать квадрат разности между предсказанными и реальными ценами: $L(y, \\hat{y}) = \\left(y - \\hat{y}\\right)^2$. Чем меньше мера $L$, тем точнее модель предсказывает реальные цены. Использование квадрата разности обусловлено тем, что большая разница в предсказаниях дает значительно худший результат, чем небольшая разница.\n",
    "\n",
    "Другим примером может служить предсказание невозврата кредита клиентом банка. Исходя из исторических данных можно построить модель, которая в зависимости от характеристик клиента будет предсказывать вероятность невозврата. В качестве характеристик клиента можно взять возраст, доход, количество детей или иждивенцев, историю кредитов и т.д. Эти характеристики соответствуют опыту $E$. Задачей $T$ является предсказания возврата или невозврата. В качестве меры $L$ можно использовать разницу предсказанной вероятности невозврата от единицы для клиентов, которые реально не возвращали кредит.\n",
    "\n",
    "### Обучение с учителем (supervised learning)\n",
    "Обучение с учителем это вид машинного обучения, когда алгоритму подается набор размеченных данных (labeled data), из которых алгоритм выводит функцию, которая затем используется для предсказания целевой величины на новых данных. Оба приведенных выше примера являются примерами обучения с учителем.\n",
    "\n",
    "#### Регрессия (regression)\n",
    "В первом примере с ценой квартиры необходимо было предсказать действительное число (т.е. цену). Задачи, в которых нужно предсказать действительное число, называются задачей регрессии. Например, все задачи, в которых нужно предсказать цену относятся к задачам регрессии. \n",
    "\n",
    "#### Классификация (classification)\n",
    "Во втором примере один из двух классов возврат/невозврат.  Задачи, в которых нужно предсказать одну из дискретных классов, называются задачами классификации. Примерами задач классификации являются спам фильтры, классификация изображений, определение эмоционального оттенка (тональности) текста. Задача классификации, где нужно предсказать один из двух классов, называется бинарной классификацией.\n",
    "\n",
    "### Обучение без учителя (unsupervised learning)\n",
    "Обучение без учителя это вид машинного обучения, когда алгоритму подается набор неразмеченных данных, из которых алгоритм сам находит некоторые закономерности. Примером обучения без учителя является кластеризация, когда данные разбиваются на несколько кластеров по каким либо характерным признакам. Например, покупатели магазина могут быть разделены на различные кластеры в зависимости от истории покупок. Word2vec, широко используемый для анализа естественных языков, также является примером обучения без учителя.\n",
    "\n",
    "## Модель машинного обучения с учителем\n",
    "Как было сказано выше, алгоритмы машинного обучения обучаются путем выявления закономерностей (паттернов) в данных. Формально эту закономерность можно представить как функцию, которая на вход принимает данные $\\vec{x}$ (например, параметры квартиры) и на выходе дает целевое значение $\\hat{y}$ (например, цену квартиры): \n",
    "$$\\large \\hat{y} = h(\\vec{x}, \\vec{\\theta})$$\n",
    "У функции $h$ есть набор параметров $\\vec{\\theta}$. Благодаря этим параметрам модель может адаптироваться к различным наборам данным и делать предсказания для различных задач. Собственно подбор наиболее оптимальных значений параметров модели для конкретного набора данных и называется обучением.\n",
    "\n",
    "Обратите внимание, что мы опредилили функцию $h$ в очень общем виде. В самом деле функция $h$ может представлять из себя как простую модель линейной регрессии, так и очень сложную глубокую нейронную сеть. При этом общая концепция остается одинаковой: подобрать параметры модели $h$ так, чтобы предсказанные значения были наиболее точными.\n",
    "\n",
    "### Линейная регрессия\n",
    "Одной из простейших моделей машинного обучения (т.е. конкретная реализация функции $h(\\vec{x}, \\vec{\\theta})$) является линейная регрессия. Несмотря на свою простоту у этого метода есть несколько очень важных свойств:\n",
    "1. Будучи очень простой моделю, её относительно легко анализировать и на её примере легко понять концептуально как работают модели машинного обучения. \n",
    "2. Более сложные модели основываются на линейной модели. Например, логистическая регрессия является простейшей моделью бинарной классификации и основывается на линейной регрессии. Каждый отдельный слой нейронной сети также представляет из себя линейную модель. \n",
    "3. Линейная регрессия используется во <a href=\"https://en.wikipedia.org/wiki/Linear_regression#Applications_of_linear_regression\">многих прикладных задачах</a>. \n",
    "4. Линейная регрессия пожалуй единственная модель машинного обучения, которая может быть выражена в виде аналитической формулы.\n",
    "\n",
    "Линейная регрессия предполагает, что зависимость между данными $\\vec{x}$ и целевой переменной $y$ является линейной и представляет $y$ как сумму элементов вектора $\\vec{x}$:\n",
    "$$\\hat{y} = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\cdots + \\theta_n x_n$$\n",
    "С помощью скалярного произведения векторов (vector dot product) данное выражение можно записать короче. Для этого мы предполагаем что $x_0=1$, чтобы параметр $\\theta_0$ также был включен в это произведение:\n",
    "$$\\hat{y} = \\theta_0 x_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\cdots + \\theta_n x_n = \\sum_{i=0}^{n}\\theta_i x_i = \\vec{x}^T\\vec{\\theta}$$\n",
    "Допустим в примере с предсказанием цены квартиры её площадь равна **42 кв. м.** и она расположена на **четвертом** этаже, а её цена составляет **30 000**. В таком случае основываясь на этих данных мы можем записать модель линейной регрессии следующим образом:\n",
    "$$30000 = \\theta_0 + 42 \\theta_1  + 4 \\theta_2$$\n",
    "Задачей обучения является найти такие параметры $\\vec{\\theta}=(\\theta_0, \\theta_1, \\theta_2)$, при которых разница между реальными и предсказанными ценами была бы минимальной. \n",
    "\n",
    "Однако для подбора параметров необходимо иметь много таких примеров. Допустим у нас есть $m$ примеров: $\\vec{x_1}, \\vec{x_2} \\cdots \\vec{x_m}$ и $y_1, y_2 \\cdots y_m$. Тогда для каждого из них можно записать следующие выражения:\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\hat{y_1} &= \\theta_0 x_{1,0} &+ \\theta_1 x_{1,1} + &\\cdots &+ \\theta_n x_{1,n} \\\\\n",
    "    \\hat{y_2} &= \\theta_0 x_{2,0} &+ \\theta_1 x_{2,1} + &\\cdots &+ \\theta_n x_{2,n} \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    \\hat{y_m} &= \\theta_0 x_{m,0} &+ \\theta_1 x_{m,1} + &\\cdots &+ \\theta_n x_{m,n} \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "Как видно запись в такой форме является очень громоздкой. Вместо этого векторы $\\vec{x_1}, \\vec{x_2} \\cdots \\vec{x_m}$ можно представить в виде матрицы $X$:\n",
    "$$\n",
    "\\begin{align}\n",
    "X &= (\\vec{x_1}, \\vec{x_2}, \\ldots, \\vec{x_m}) &= \\begin{pmatrix}\n",
    "        x_{1,0} & x_{1,2} & \\cdots & x_{1,n} \\\\\n",
    "        x_{2,0} & x_{2,2} & \\cdots & x_{2,n} \\\\\n",
    "        \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "        x_{m,0} & x_{m,2} & \\cdots & x_{m,n} \\\\\n",
    "     \\end{pmatrix}\n",
    "\\end{align}\n",
    "$$\n",
    "Целевые переменные $y_1, y_2 \\cdots y_m$ представим как вектор $\\vec{y}$:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\vec{y} &= \\begin{bmatrix}\n",
    "        y_1 \\\\\n",
    "        y_2 \\\\\n",
    "        \\vdots \\\\\n",
    "        y_m\n",
    "     \\end{bmatrix}\n",
    "\\end{align}\n",
    "$$\n",
    "Тогда линейная регрессия в векторном виде может быть записана как поизведение матрицы $X$ на вектор параметров $\\vec{\\theta}$\n",
    "$$\n",
    "\\Large \\hat{\\vec{y}} = X \\vec{\\theta} \\tag{1}\n",
    "$$\n",
    "Допустим, что у нас помимо примера квартиры, которая была приведена выше, есть еще две записи: 60 кв.м. на первом этаже и 55 кв.м. на девятом. Тогда наша матрица $X$ будет выглядеть следующим образом:\n",
    "$$\n",
    "\\begin{align}\n",
    "X &= \\begin{pmatrix}\n",
    "        1 & 42 & 4 \\\\\n",
    "        1 & 60 & 1 \\\\\n",
    "        1 & 55 & 9\n",
    "     \\end{pmatrix}\n",
    "\\end{align}\n",
    "$$\n",
    "Пусть цены этих двух квартир составляют 50000 и 45000 соответственно. Тогда $\\vec{y}$\n",
    "$$\n",
    "\\begin{align}\n",
    "\\vec{y} &= \\begin{bmatrix}\n",
    "        30000 \\\\\n",
    "        50000 \\\\\n",
    "        45000\n",
    "     \\end{bmatrix}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "### Среднеквадратическая ошибка (mean squared error)\n",
    "> Нельзя улучшить то, что нельзя измерить\n",
    "\n",
    "> *Лорд Кельвин*\n",
    "\n",
    "Следующей задачей является поиск таких параметров $\\vec{\\theta}$, при которых значение вектора $\\hat{\\vec{y}}$ будет наиболее близким к фактическому значению вектора $\\vec{y}$. Чтобы оценить ошибку предсказания модели будем использовать средквадратическую ошибку:\n",
    "$$\n",
    "\\Large \n",
    "L = \\frac{1}{2n} \\sum_{i=1}^n \\left(y_i - \\hat{y_i}\\right)^2 \\tag{2}\n",
    "$$\n",
    "В данной формуле мы для каждого примера из нашего набора данных вычисляем соответствующее значение $\\hat{y_i}$, вычисляем разницу между предсказанным и фактическим значениями и затем возводим эту разницу в квадрат. Наконец мы суммируем все вычисленные квадраты и делем на количество примеров. Таким образом мы получаем среднее значение квадратов разниц. \n",
    "\n",
    "Используя векторную форму линейной регресси (1) мы можем записать среднеквадратическую ошибку в векторной форме:\n",
    "$$\n",
    "\\Large L = \\frac{1}{2n} \\left\\| \\vec{y} - X \\vec{\\theta} \\right\\|_2^2 \\tag{3}\n",
    "$$\n",
    "Давайте разберем эту формулу детально. Выражение $X \\vec{\\theta}$ дает нам предсказанные значения $\\hat{\\vec{y}}$. Поэтому выражение $\\vec{y} - X \\vec{\\theta}$ вычисляет разницу между $\\vec{y}$ и $\\hat{\\vec{y}}$. Как мы видели во введении в линейную алгебру выражение $\\left\\|\\vec{w}\\right\\|$ обозначает евклидовую длину вектора $\\vec{w}$, которая равна квадратному корню из суммы квадратов элементов этого вектора: $\\sqrt{w_1^2 + w_2^2 + \\cdots + w_n^2}$. Соответственно выражение $\\left\\| \\vec{y} - X \\vec{\\theta} \\right\\|_2^2$ обозначает сумму квадратов разниц между $\\vec{y}$ и $\\hat{\\vec{y}}$.\n",
    "\n",
    "Теперь нашей задачей является нахождение таких параметров $\\vec{\\theta}$, при которых среднеквадратическая ошибка (3) будет наименьшей. Следующее выражение формулирует это предложение математически:\n",
    "$$\n",
    "\\Large \\arg \\min_{\\vec{\\theta}} L\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
